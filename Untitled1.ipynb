{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5dfdd8-db06-4ec3-995c-bb59c2840f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = \"\"\"file    main_full    discipline    private_vb    that_del    contract    vb_present    pro_2    do_pro    pro_dem    emphatic    pro_1    pro_it    vb_be    sub_conj_caus    discipline    ... (other columns)\n",
    "0004d    to argue    SS    6.3    0.3    1.9    89.4    0    0.2    5.1    1    4    13.5    2.1    3.1    0    0.8    0    0.8    0.2    6.2    8.8    1.1    0.5    280.8    136.6    84.9    11.7    18.6    4.8    4.8    1.4    4.7    4.8    4.2    87.8    2.8    1.2    30.7    9.7    7.6    1.4    1.9    3.2    2.8    10.7    16.8    1.9    2.7    4    10    3.8    8.8    17.1    22    21.3    1.3    10.8    113.7    22.6    2.7    113.8    3.4    7.8    0.2    0    0.9    0    6.9    1.6    6.3    2.7    1.5    1.4    10.9    3.1    5.3    1.2    3.4    21.2    69.7    1.9    168    23.5    15.4    0.2    0    0    1.3    0.2    0.4    0.1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    7.2    0.3    2.5    0.4    0    0    0    0    0.1    0.9    1    0.1    0.4    0.4    2.9    0.7    0.1    0    0    0.1    0    2.7    0.1    0.1    1.5    0.4    0    10.4    0    1.9    12.4    4.5    0.2    7.4    2    0    0.2    0    0.2    0    0    0.1    3.2    15.1    13.3    38.8    3.5    2.1    2.7    1.3    0.4    0.3    1.5    0    0    3.9    11.3    15.9    10    8.7    2    5.1    6.4    0.9    0    -15.17    -2.71    13.21    -0.81    7.92    31.5    5.4    10263    35.37    2.05    81.26    12.28    4.97    0.78    9.26    0.1    4.09    0    14.42    3.9    2.05    2.44    0    1.56    0    0.49\"\"\"\n",
    "\n",
    "# Split the data into lines\n",
    "lines = data.strip().split('\\n')\n",
    "header = lines[0].split()  # Split the first line to get column titles\n",
    "values = lines[1].split()  # Split the second line to get values\n",
    "\n",
    "# Combine column titles and values\n",
    "combined_data = [f\"{header[i]}\\t{values[i]}\" for i in range(len(header))]\n",
    "\n",
    "# Save to a text file\n",
    "with open('data.txt', 'w') as file:\n",
    "    file.write('\\n'.join(combined_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22c9de-c7ff-4e12-b993-19bdeafd4490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ingridveloso/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.1.175:5002/ (Press CTRL+C to quit)\n",
      "192.168.1.175 - - [20/Oct/2023 22:06:19] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.175 - - [20/Oct/2023 22:06:26] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from flask import Flask, request, render_template\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='app.log', level=logging.DEBUG)\n",
    "\n",
    "# Load your CSV data into a Pandas DataFrame\n",
    "data = pd.read_csv('bibertrain.csv')\n",
    "\n",
    "# Extract features (numerical frequencies) and target (purpose)\n",
    "X = data.iloc[:, 3:]  # Assuming feature columns start from the fourth column\n",
    "y = LabelEncoder().fit_transform(data['main_full'])\n",
    "\n",
    "# Create and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "app = Flask(__name__, template_folder='./')\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def predict_discipline():\n",
    "    if request.method == 'POST':\n",
    "        uploaded_file = request.files['file']\n",
    "        if uploaded_file:\n",
    "            try:\n",
    "                input_data = pd.read_csv(uploaded_file)\n",
    "                logging.debug(\"Input Data:\")\n",
    "                logging.debug(input_data)\n",
    "\n",
    "                # Predict the purpose/discipline based on the uploaded features\n",
    "                prediction = model.predict(input_data)\n",
    "                discipline = LabelEncoder().inverse_transform(prediction)[0]\n",
    "                logging.debug(f\"Prediction Result: {discipline}\")\n",
    "                return render_template('index.html', discipline=discipline)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Prediction Error: {str(e)}\")\n",
    "    \n",
    "    return render_template('index.html', discipline=None)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5002)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456c88c-e68a-4ef3-a49e-fff98e13ed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07862c44-3f89-4ba7-ba7c-16c17b905f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ingridveloso/opt/anaconda3/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/ingridveloso/opt/anaconda3/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/bv/0q0q47mj5_b9cqh241y0_s4h0000gn/T/ipykernel_34425/1105412616.py\", line 13, in start_flask_app\n",
      "AttributeError: 'Flask' object has no attribute 'webapp'\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "import threading\n",
    "\n",
    "# Function to start Flask app and ngrok when running in Colab\n",
    "def start_flask_app():\n",
    "    # Your Flask application code goes here\n",
    "    app = Flask(__name__)\n",
    "\n",
    "    @app.route('/')\n",
    "    def hello():\n",
    "        return \"Hello, world!\"\n",
    "\n",
    "    app.add_url_rule('/ngrok', 'webapp', app.webapp)\n",
    "\n",
    "    # Start ngrok when app is run\n",
    "    public_url = ngrok.connect(port='5000')\n",
    "    print(' * ngrok tunnel \"', public_url, '\"')\n",
    "\n",
    "# Start the Flask app in a separate thread\n",
    "thread = threading.Thread(target=start_flask_app)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec7963b8-1873-4a0b-837d-bfd650520137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your training data to determine the column order\n",
    "training_data = pd.read_csv('bibertrain.csv')  # Replace with your training file\n",
    "\n",
    "# Read the input CSV file\n",
    "input_data = pd.read_csv('bibertrain-Copy1.csv')  # Replace with your input file\n",
    "\n",
    "# Reorder the columns of the input data to match the training data\n",
    "input_data = input_data[training_data.columns]\n",
    "\n",
    "# Save the formatted input data to a new CSV file\n",
    "input_data.to_csv('formatted_input_data.csv', index=False)  # Replace with your desired output file name\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
